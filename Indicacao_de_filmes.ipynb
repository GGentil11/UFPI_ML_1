{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ggentil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ggentil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ggentil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ggentil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"[^\\w\\s]\", \"\", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    texto = \" \".join([lemmatizer.lemmatize(word) for word in texto.split() if word not in stop_words])\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_similaridade_cosine(indice_filme, matriz_tfidf):\n",
    "    return cosine_similarity(matriz_tfidf[indice_filme], matriz_tfidf).flatten()\n",
    "\n",
    "def jaccard_similaridade(indice_filme, df_rec):\n",
    "    conjunto1, conjunto2 = set(indice_filme.split()), set(df_rec.split())\n",
    "    return len(conjunto1.intersection(conjunto2)) / len(conjunto1.union(conjunto2))\n",
    "\n",
    "def calcular_similaridade_jaccard(indice_filme, df_rec):\n",
    "    texto_filme = df_rec['colunas_combinadas_pre'].iloc[indice_filme]\n",
    "    return np.array([jaccard_similaridade(texto_filme, texto) for texto in df_rec['colunas_combinadas_pre']])\n",
    "\n",
    "def calcular_similaridade_levenshtein(indice_filme, df_rec):\n",
    "    texto_filme = df_rec['colunas_combinadas_pre'].iloc[indice_filme]\n",
    "    return np.array([1 / (1 + levenshtein_distance(texto_filme, texto)) for texto in df_rec['colunas_combinadas_pre']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_similaridades(indice_filme, matriz_tfidf, df_rec):\n",
    "    similaridades_cosine = calcular_similaridade_cosine(indice_filme, matriz_tfidf)\n",
    "    similaridades_jaccard = calcular_similaridade_jaccard(indice_filme, df_rec)\n",
    "    similaridades_levenshtein = calcular_similaridade_levenshtein(indice_filme, df_rec)\n",
    "\n",
    "    similaridades_cosine = (similaridades_cosine - np.min(similaridades_cosine)) / (np.max(similaridades_cosine) - np.min(similaridades_cosine))\n",
    "    similaridades_jaccard = (similaridades_jaccard - np.min(similaridades_jaccard)) / (np.max(similaridades_jaccard) - np.min(similaridades_jaccard))\n",
    "    similaridades_levenshtein = (similaridades_levenshtein - np.min(similaridades_levenshtein)) / (np.max(similaridades_levenshtein) - np.min(similaridades_levenshtein))\n",
    "    \n",
    "    similaridades_agregadas = similaridades_cosine + similaridades_jaccard + similaridades_levenshtein\n",
    "    return similaridades_agregadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_filme(filme_assistido, df_rec, matriz_tfidf, n_recomendacoes):\n",
    "    try:\n",
    "        if filme_assistido.lower() not in df_rec['Series_Title'].str.lower().values:\n",
    "            return print(f\"Filme '{filme_assistido}' não encontrado no dataset.\")\n",
    "\n",
    "        indice_filme = df_rec[df_rec['Series_Title'].str.lower() == filme_assistido.lower()].index[0]\n",
    "        similaridades_agregadas = calcular_similaridades(indice_filme, matriz_tfidf, df_rec)\n",
    "\n",
    "        indices_similares = similaridades_agregadas.argsort()[-(n_recomendacoes+1):][::-1]\n",
    "        indices_similares = indices_similares[indices_similares != indice_filme]\n",
    "        filmes_recomendados = df_rec['Series_Title'].iloc[indices_similares].tolist()\n",
    "        return filmes_recomendados\n",
    "\n",
    "    except Exception as e:\n",
    "        return print(f\"Ocorreu um erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dataset():\n",
    "    # Carregar o dataset de filmes\n",
    "    df_rec = pd.read_csv(\"dados_tratados.csv\")\n",
    "\n",
    "    # Aplicar pré-processamento na coluna \"colunas_combinadas\"\n",
    "    df_rec['colunas_combinadas'] = df_rec.apply(lambda x: f\"{x['Series_Title']} {x['Certificate']} {x['Genre']} {x['Overview']} {x['Director']}\", axis=1)\n",
    "    df_rec['colunas_combinadas_pre'] = df_rec['colunas_combinadas'].apply(pre_processamento_texto)\n",
    "\n",
    "    # Vetorizar TF-IDF para \"colunas_combinadas_pre\"\n",
    "    vetor_tfidf = TfidfVectorizer()\n",
    "    matriz_tfidf = vetor_tfidf.fit_transform(df_rec['colunas_combinadas_pre'])\n",
    "\n",
    "    # Processamento dos gêneros usando MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    generos_codificados = mlb.fit_transform(df_rec['Genre'].apply(lambda x: x.split(\", \")))\n",
    "\n",
    "    # Concatenar matriz TF-IDF com vetores de gênero usando hstack\n",
    "    matriz_tfidf_com_generos = hstack([matriz_tfidf, generos_codificados.astype(float)])\n",
    "\n",
    "    # Aplicar Chi-Quadrado\n",
    "    seletor = SelectKBest(chi2, k=1000)\n",
    "    matriz_tfidf_com_generos_reduzida = seletor.fit_transform(matriz_tfidf_com_generos, generos_codificados)\n",
    "    return df_rec, matriz_tfidf_com_generos, matriz_tfidf_com_generos_reduzida, generos_codificados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df_rec, matriz_tfidf_com_generos, matriz_tfidf_com_generos_reduzida, generos_codificados = preparar_dataset()\n",
    "    \n",
    "    # Solicitar ao usuário o nome do filme assistido\n",
    "    filme_assistido = input(\"Digite o nome do filme assistido: \").strip()\n",
    "\n",
    "    # Validar entrada do usuário\n",
    "    if not filme_assistido:\n",
    "        print(\"Por favor, insira um título de filme válido.\")\n",
    "    else:\n",
    "        # Obter recomendações usando a matriz TF-IDF com gêneros reduzida\n",
    "        filmes_recomendados = recomendar_filme(filme_assistido, df_rec, matriz_tfidf_com_generos_reduzida, n_recomendacoes=8)\n",
    "\n",
    "        # Imprimir recomendações se houver\n",
    "        if filmes_recomendados:\n",
    "            print(f\"Filmes Recomendados para '{filme_assistido}':\")\n",
    "            for filme in filmes_recomendados:\n",
    "                print(f\"- {filme}\")\n",
    "\n",
    "            # Dividir dados para treinamento e teste\n",
    "            X_treino, X_teste, y_treino, y_teste = train_test_split(matriz_tfidf_com_generos, generos_codificados, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Configurar e treinar SVM com Grid Search para otimização de parâmetros\n",
    "            param_grid = {'estimator__C': [0.1, 1, 10], 'estimator__kernel': ['linear', 'rbf']}\n",
    "            grid_search = GridSearchCV(OneVsRestClassifier(SVC()), param_grid, cv=5)\n",
    "            grid_search.fit(X_treino, y_treino)\n",
    "\n",
    "            # Usar cross_val_score para avaliar o modelo\n",
    "            scores = cross_val_score(grid_search.best_estimator_, matriz_tfidf_com_generos, generos_codificados, cv=5, scoring='accuracy')\n",
    "            print(\"_________________________________________________________________\")\n",
    "            print(f\"Validação Cruzada Acurácia: {np.mean(scores)}\")\n",
    "\n",
    "            # Avaliar o modelo nos dados de teste\n",
    "            y_pred = grid_search.predict(X_teste)\n",
    "            print(f\"Acurácia do SVM: {accuracy_score(y_teste, y_pred)}\")\n",
    "            print(f\"Melhores parâmetros: {grid_search.best_params_}\")\n",
    "            print(f\"Precisão: {precision_score(y_teste, y_pred, average='weighted')}\")\n",
    "            print(f\"Recall: {recall_score(y_teste, y_pred, average='weighted')}\")\n",
    "            print(f\"F1-score: {f1_score(y_teste, y_pred, average='weighted')}\")\n",
    "\n",
    "            # Relatório de classificação\n",
    "            print(\"\\nRelatório de Classificação:\")\n",
    "            print(classification_report(y_teste, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filmes Recomendados para 'The Godfather':\n",
      "- The Godfather: Part III\n",
      "- The Godfather: Part II\n",
      "- Un prophète\n",
      "- Casino\n",
      "- Scarface\n",
      "- Once Were Warriors\n",
      "- Drive\n",
      "- La haine\n",
      "_________________________________________________________________\n",
      "Validação Cruzada Acurácia: 1.0\n",
      "Acurácia do SVM: 1.0\n",
      "Melhores parâmetros: {'estimator__C': 1, 'estimator__kernel': 'linear'}\n",
      "Precisão: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        48\n",
      "           2       1.00      1.00      1.00        20\n",
      "           3       1.00      1.00      1.00        27\n",
      "           4       1.00      1.00      1.00        42\n",
      "           5       1.00      1.00      1.00        31\n",
      "           6       1.00      1.00      1.00       145\n",
      "           7       1.00      1.00      1.00         9\n",
      "           8       1.00      1.00      1.00         9\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00        13\n",
      "          11       1.00      1.00      1.00         7\n",
      "          12       1.00      1.00      1.00        10\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00        23\n",
      "          15       1.00      1.00      1.00        21\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00        30\n",
      "          19       1.00      1.00      1.00         7\n",
      "          20       1.00      1.00      1.00         4\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       509\n",
      "   macro avg       1.00      1.00      1.00       509\n",
      "weighted avg       1.00      1.00      1.00       509\n",
      " samples avg       1.00      1.00      1.00       509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
